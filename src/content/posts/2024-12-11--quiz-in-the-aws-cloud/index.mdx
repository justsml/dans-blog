---
unlisted: false
title: "Quiz: AWS Storage: 20 Questions!"
subTitle: "Can you navigate the labyrinth?"
label: AWS Storage
category: Quiz
subCategory: Cloud
date: 2024-12-11
modified: 2024-12-20
tags: [quiz, aws, cloud, storage, databases, s3, dynamodb, rds, elasticache]

cover_full_width: aws-cloud--city-focus-wide.webp
cover_mobile: aws-cloud--city-focus-square.webp
cover_icon: aws-cloud--city-focus-square.webp
---
import Challenge from '../../../components/QuizUI/Challenge';
import QuizUI from '../../../components/QuizUI/QuizUI';

<p class="inset">Are you down to cloud?!</p>

Dive deep into AWS Storage Services! This quiz will test your knowledge of S3, DynamoDB, Aurora, RDS, ElastiCache, and more. From best practices to tricky gotchas, we'll explore the cloud storage landscape.

Get ready to prove your cloud expertise! üöÄ

<QuizUI>

<Challenge
  client:load
  index={0}
  group="Warmup"
  title="S3 Trivia"
  options={[
    { text: "Server Storage v3" },
    { text: "Storage as a Service" },
    { text: "Simple Storage Service", isAnswer: true },
    { text: "Sassy Storage Service" },
    { text: "Simple Synchronized Store" },
  ]}
>
  <slot name="question">
  <div className="question">
    What does the name `S3` mean?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  S3 stands for **Simple Storage Service**. It's a scalable object storage service designed for large-scale data storage.

  AWS S3 offers multiple storage classes:
  - Standard: For frequently accessed data
  - Infrequent Access (IA): Lower cost for less frequent access
  - Glacier: Long-term, low-cost archival storage

  Each class offers different pricing and access characteristics, allowing cost optimization based on data usage patterns.

  [Learn more about S3 Storage Classes](https://aws.amazon.com/s3/storage-classes/)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={1}
  group="Schema less"
  title="DynamoDB"
  options={[
    { text: "Columns are untyped" },
    { text: "Dynamic partition keys" },
    { text: "Store arbitrary properties", isAnswer: true },
    { text: "Automatically managed JSON schema" },
    { text: "Relies on RDS for schema support" },
  ]}
>
  <slot name="question">
  <div className="question">
    What does it mean when DynamoDB is described as "schema-less"?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  DynamoDB is considered "schema-less" because it allows you to store arbitrary properties in items without a predefined schema.

  [DynamoDB Best Practices](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={2}
  group="Schema less"
  title="DynamoDB"
  options={[
    { text: "PutItem", hint: "Creates a new item, or replaces an old item with a new item." },
    { text: "UpdateItem", isAnswer: true },
    { text: "BatchWriteItem", hint: "Puts (inserts) OR deletes multiple items in a single call."  },
    { text: "BatchUpdateItem", hint: "Does not exist." },
    { text: "BatchUpsertItem", hint: "In DynamoDB?" },
    { text: "TransactWriteItems", hint: "Combines multiple PutItem, UpdateItem, DeleteItem, and ConditionCheck operations into a single call." },
    ]}
>
  <slot name="question">
  <div className="question">
    Most scalable way to handle many UPDATES to DynamoDB? (for example, backfilling a `status=active` column.)
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  The key here is <b>updates</b>, not inserts or PUTs. If you're doing inserts, you can use `BatchWriteItem` or `TransactWriteItems`.

  While `BatchWriteItem` can handle multiple operations, it's limited to PUTs and DELETES. `TransactWriteItems` is more powerful, but it's a bit of a sledgehammer for simple updates.
  For simple updates, `UpdateItem` is the best choice. It allows you to UPDATE, or modify one or more attributes in an existing item.

  The `UpdateItem` operation is the best way to handle multiple updates. It allows you to modify one or more attributes in an existing item.

  The `UpdateItem` operation:
  - Updates an existing item's attributes.
  - Adds new attributes to an existing item.
  - Removes attributes from an existing item.
  - Conditionally performs the update if the item exists or meets certain conditions.

  [DynamoDB UpdateItem](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_UpdateItem.html)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={3}
  group="Data Querying"
  title="Searchability"
  options={[
    { text: "S3", hint: "S3+Athena let's you query S3 objects!" },
    { text: "RDS", hint: "SQL service..." },
    { text: "Aurora", hint: "SQL service..." },
    { text: "Snorlax", isAnswer: true },
    { text: "DynamoDB", hint: "NoSQL can support SQL-style queries." },
    { text: "CloudWatch", hint: "Monitoring service..." },
    { text: "CloudTrail", hint: "Supports querying logs, often slowly." },
  ]}
>
  <slot name="question">
  <div className="question">
    Which of these services CANNOT ‚ùå perform **SQL-style** queries?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  This one is a little tricky. It assumes you've got operator-level experience with some of these services.

  1. Not many folks know S3 objects can be queried (w/ Athena.) Supports several formats, including CSV, JSON+LD, and Parquet.
  2. RDS, Aurora, and DynamoDB are traditional databases that support SQL-like queries.
  3. CloudWatch and CloudTrail are monitoring services, however they both support querying logs. Output logs in JSON to get granular column-level filtering.

  In the world of Graph Databases, you're **not querying rows and columns**, you're querying **vertices and edges.** This hints at a fundamentally different way of thinking about data. Using a term like "row" instead of "vertex" in the wrong context _could_ reveal your lack of experience to an expert or interviewer. üòÖ
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={4}
  group="RDS"
  title="Multi-AZ Deployment"
  options={[
    { text: "Reduces storage costs" },
    { text: "Solves the Egress Problem" },
    { text: "Increases read performance" },
    { text: "Provides automatic failover", isAnswer: true },
    { text: "Improves geo-distributed traffic" },
  ]}
>
  <slot name="question">
  <div className="question">
    What is the **primary** benefit of RDS Multi-AZ deployment?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  Availability Zones (AZs) are distinct data centers **within a region.** RDS Multi-AZ deployment provides automatic failover to a standby replica in a *nearby* AZ.

  Multi-AZ deployment:
  - Provides automatic failover
  - Increases database availability
  - Creates a synchronous standby replica
  - Minimizes downtime during infrastructure failures

  Don't confuse Multi-AZ deployment with Read Replicas, which are used for scaling read operations.

  {/* [RDS Multi-AZ Details](https://aws.amazon.com/rds/features/multi-az/) */}
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={3}
  group="Data Querying"
  title="Searchability"
  difficulty="medium"
  learningObjectives={[
    "Get familiar with the query powers of different AWS services",
    "Know which services support SQL-style queries",
  ]}
  options={[
    { text: "S3", hint: "S3+Athena = query magic" },
    { text: "RDS", hint: "SQL all the way" },
    { text: "Aurora", hint: "Another SQL superstar" },
    { text: "Simple Notification Service", isAnswer: true },
    { text: "DynamoDB", hint: "NoSQL with a SQL twist" },
    { text: "CloudWatch", hint: "Query those logs like a pro" },
    { text: "CloudTrail", hint: "Logs, but slower" },
  ]}
>
  <slot name="question">
    <div className="question">
      Which AWS service is **not** capable of performing SQL-style queries?
    </div>
  </slot>

  <slot name="explanation">
    <div className="explanation">
      <p>
        So, you wanna know which AWS service doesn't do SQL-style queries? Well, let's break it down. S3 + Athena is a query powerhouse, and RDS, Aurora, and DynamoDB are all about SQL-like queries. CloudWatch and CloudTrail, yeah, they're all about logging, but you can still query those logs in clever ways.
      </p>
      <p>
        Simple Notification Service, on the other hand, is a messaging service that enables fan-out messaging and EventBus. It's not designed for querying data, so it's the correct answer! üòâ
      </p>
    </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={6}
  group="DynamoDB: Batch!"
  title="Batch Operations"
  options={[
    { text: "1", isAnswer: true },
    { text: "10" },
    { text: "25", hint: "Close..." },
    { text: "50" },
    { text: "100", hint: "Thinking of GetItem limit?" },
    { text: "Unlimited when streaming" },
    { text: "None of the above" },
  ]}
>
  <slot name="question">
  <div className="question">
    What's the maximum number of documents the DynamoDB SDK can send per HTTP `PUT` request?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  The DynamoDB Clients are essentially all wrappers for the REST API.
  
  The DynamoDB SDK can send **25** documents per HTTP `PUT` request. This is the default limit for batch operations.
  {/* will accept **25** documents per HTTP `PUT` request. This is the default limit for batch operations. */}

  </div>
  </slot>
</Challenge>
  
  
<Challenge
  client:load
  index={7}
  group="S3 Security"
  title="S3 Bucket Policy"
  options={[
    { text: "Always make buckets public" },
    { text: "Use least privilege principle", isAnswer: true },
    { text: "Disable all security" },
    { text: "Use maximum permissions" }
  ]}
>
  <slot name="question">
  <div className="question">
    What's the recommended approach to S3 bucket permissions?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  In virtually ALL systems, embracing a "least privilege" design is a key way to harden & future proof. Trying to lock down an existing system is about as difficult as moving an entire office building to a new foundation.

  S3 buckets are no exception. To apply the principle of least privilege, start with no permissions and grant only the necessary access. Use IAM roles and policies to control access and regularly audit bucket permissions.

  Security best practices:
  - Apply least privilege principle
  - Start with no permissions
  - Grant only necessary access
  - Use IAM roles and policies
  - Regularly audit bucket permissions

  Avoid overly permissive settings that could expose sensitive data.

  [S3 Security Best Practices](https://aws.amazon.com/s3/security/)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={8}
  group="Aurora"
  title="Aurora Serverless"
  options={[
    { text: "Always cheaper than provisioned" },
    { text: "Automatically scales compute capacity", isAnswer: true },
    { text: "Provides unlimited storage" },
    { text: "Eliminates database management" }
  ]}
>
  <slot name="question">
  <div className="question">
    What is the key feature of Aurora Serverless?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  Aurora Serverless:
  - Automatically scales compute capacity
  - Adjusts resources based on workload
  - Ideal for unpredictable workloads
  - Pay only for used resources

  Great for applications with variable traffic patterns.

  [Aurora Serverless Overview](https://aws.amazon.com/rds/aurora/serverless/)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={9}
  group="DynamoDB"
  title="Provisioned vs On-Demand Capacity"
  options={[
    { text: "Provisioned is always better" },
    { text: "On-demand is cheaper for unpredictable workloads", isAnswer: true },
    { text: "They perform identically" },
    { text: "On-demand has unlimited capacity" }
  ]}
>
  <slot name="question">
  <div className="question">
    When should you use DynamoDB On-Demand capacity?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  On-Demand Capacity is best for:
  - Unpredictable workloads
  - Sporadic traffic
  - Applications with unknown access patterns
  - Avoiding over-provisioning

  Provisioned capacity is better for:
  - Predictable, consistent workloads
  - More control over performance
  - Potential cost savings

  [DynamoDB Capacity Modes](https://aws.amazon.com/dynamodb/pricing/)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={10}
  group="S3 Performance"
  title="S3 Performance Optimization"
  options={[
    { text: "Use sequential prefixes" },
    { text: "Use random/hash prefixes", isAnswer: true },
    { text: "Always use largest objects" },
    { text: "Minimize number of objects" }
  ]}
>
  <slot name="question">
  <div className="question">
    How to optimize S3 performance for high request rates?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  S3 Performance Tips:
  - Use random/hash prefixes in object keys
  - Prevents "hot" partitions
  - Distributes load across S3 infrastructure
  - Improves request distribution

  Avoid sequential prefixes which can create bottlenecks.

  [S3 Performance Guidelines](https://aws.amazon.com/s3/performance/)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={11}
  group="RDS Backup"
  title="RDS Backup Strategy"
  options={[
    { text: "Manual snapshots only" },
    { text: "Automated backups with point-in-time recovery", isAnswer: true },
    { text: "No backups needed" },
    { text: "Weekly full backups" }
  ]}
>
  <slot name="question">
  <div className="question">
    What's the recommended RDS backup approach?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  Best Backup Practices:
  - Enable automated backups
  - Use point-in-time recovery
  - Retain backups based on compliance needs
  - Test restoration process regularly
  - Consider cross-region backup

  Automated backups provide:
  - Continuous data protection
  - Flexible recovery options

  [RDS Backup Best Practices](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_CommonTasks.BackupRestore.html)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={12}
  group="ElastiCache"
  title="Redis vs Memcached"
  options={[
    { text: "Identical in all aspects" },
    { text: "Redis supports complex data structures", isAnswer: true },
    { text: "Memcached is always faster" },
    { text: "No significant differences" }
  ]}
>
  <slot name="question">
  <div className="question">
    Key difference between Redis and Memcached in ElastiCache?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  Redis Advantages:
  - Supports complex data structures
  - Persistence options
  - Advanced operations
  - Pub/Sub messaging

  Memcached:
  - Simple key-value store
  - Pure caching
  - High performance for simple use cases

  [Redis vs Memcached](https://aws.amazon.com/elasticache/redis-vs-memcached/)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={13}
  group="DynamoDB Indexes"
  title="Global Secondary Index"
  options={[
    { text: "Identical to primary key" },
    { text: "Allows querying on non-primary attributes", isAnswer: true },
    { text: "Reduces write performance" },
    { text: "Free of additional cost" }
  ]}
>
  <slot name="question">
  <div className="question">
    Purpose of Global Secondary Index in DynamoDB?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  Global Secondary Index (GSI):
  - Allows querying on non-primary key attributes
  - Creates alternative access patterns
  - Increases query flexibility
  - Comes with additional write capacity cost

  Useful for complex query requirements beyond primary key.

  [DynamoDB Indexes](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={14}
  group="S3 Lifecycle"
  title="S3 Lifecycle Management"
  options={[
    { text: "Manually move objects" },
    { text: "Automatically transition objects between storage classes", isAnswer: true },
    { text: "Never delete old objects" },
    { text: "Store everything in Standard class" }
  ]}
>
  <slot name="question">
  <div className="question">
    What does S3 Lifecycle Management enable?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  Lifecycle Management:
  - Automatically transition objects between storage classes
  - Move infrequent data to cheaper storage
  - Set rules for object expiration
  - Optimize storage costs
  - Reduce manual management overhead

  [S3 Lifecycle Rules](https://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-configuration-examples.html)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={15}
  group="Aurora Scaling"
  title="Aurora Read Scaling"
  options={[
    { text: "Limited to single read replica" },
    { text: "Support up to 15 read replicas", isAnswer: true },
    { text: "No read scaling possible" },
    { text: "Unlimited read replicas" }
  ]}
>
  <slot name="question">
  <div className="question">
    How many read replicas can Aurora support?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  Aurora Read Replica Capabilities:
  - Up to 15 read replicas
  - Near-instantaneous replication
  - Minimal performance impact
  - Helps distribute read workloads

  Enables horizontal scaling for read-heavy applications.

  [Aurora Read Replicas](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replicas.html)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={16}
  group="RDS Security"
  title="RDS Encryption"
  options={[
    { text: "Encryption is optional" },
    { text: "Encrypt data at rest and in transit", isAnswer: true },
    { text: "No encryption available" },
    { text: "Only encrypt specific columns" }
  ]}
>
  <slot name="question">
  <div className="question">
    What encryption capabilities does RDS provide?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  RDS Encryption Features:
  - Encrypt data at rest using KMS
  - Encrypt data in transit using SSL/TLS
  - Enable encryption during database creation
  - Protect sensitive information
  - Compliance with security standards

  [RDS Encryption Options](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/encryption-options.html)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={17}
  group="DynamoDB Streams"
  title="DynamoDB Streams Purpose"
  options={[
    { text: "Store additional data copies" },
    { text: "Capture item-level changes for event-driven architectures", isAnswer: true },
    { text: "Increase write performance" },
    { text: "Replace primary tables" }
  ]}
>
  <slot name="question">
  <div className="question">
    What is the primary use of DynamoDB Streams?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  DynamoDB Streams:
  - Capture item-level changes
  - Enable event-driven architectures
  - Trigger Lambda functions
  - Support cross-region replication
  - Provide near real-time data movement

  [DynamoDB Streams Overview](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html)
  </div>
  </slot>
</Challenge>

<Challenge
  client:load
  index={18}
  group="S3 Transfer"
  title="Large File Transfer"
  options={[
    { text: "Always use single PUT request" },
    { text: "Use Multipart Upload for large files", isAnswer: true },
    { text: "Compress before uploading" },
    { text: "Split manually before upload" }
  ]}
>
  <slot name="question">
  <div className="question">
    Best method for uploading large files to S3?
  </div>
  </slot>

  <slot name="explanation">
  <div className="explanation">
  Multipart Upload Benefits:
  - Handle large files efficiently
  - Resume interrupted uploads
  - Parallel upload of file parts
  - Recommended for files > 100MB
  - Improved network reliability

  [S3 Multipart Upload](https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html)
  </div>
  </slot>
</Challenge>

</QuizUI>

Wow, that was quite a cloud storage adventure! üöÄ‚òÅÔ∏è

Think you've mastered AWS Storage Services? Keep learning and exploring!

Check out more challenges at [Cloud Mastery](/challenges/)
