---
title: "Stop Building Flaky Agents: Use Workflows & Memory"
subTitle: "Deterministic patterns for non-deterministic models."
date: 2026-01-05
modified: 2026-01-08
tags: [AI, Workflows, Memory, Mastra, Agent Networks, Orchestration]
category: AI
subCategory: Architecture
cover_full_width: ./wide.webp
cover_mobile: ./square.webp
cover_icon: ./square.webp
---

> [!NOTE]
> **Mastra v1 Beta**
>
> This article uses the Mastra v1 Beta. The APIs have been updated since the initial alpha release. Please refer to the [Mastra v1 Migration Guide](https://mastra.ai/guides/v1/migrations/upgrade-to-v1/overview) and [Getting Started Docs](https://mastra.ai/docs/home) for the latest information.

A client was trying to build a "fully autonomous" support agent.

Their plan was simple: give the LLM a bunch of tools and let it figure everything out.

It was a disaster.

The agent would hallucinate steps, skip verification, and get stuck in loops. They tried to fix it with prompt engineering. They tried to fix it with bigger models.

They were missing the point.

LLMs are non-deterministic engines. If you need a reliable business process—like processing a refund or updating a database—you cannot rely on an LLM to "vibe" its way through the steps.

You need Workflows for the rigid stuff, and Memory so your agents don't look like amnesiacs.

Let's fix this using Mastra.

---

## Workflows: The Cure for Chaos

Sometimes you don't want an agent to "think." You want it to obey.

A workflow is a deterministic pipeline: fetch data, transform it, pass it to an agent, then store the result. It's boring. Boring is good.

### When to Use Workflows
- You have a **known sequence** of steps.
- You need **observability** (logs, metrics) for each step.
- You need **retries** on flaky APIs.

### Example: The Weather Activity Planner

Let's build a workflow that fetches hard data (weather) and *then* uses an agent to interpret it.

```typescript
// src/mastra/workflows/activity-planner.ts
import { createWorkflow, createStep } from '@mastra/core/workflows';
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

// Step 1: Fetch weather data (Deterministic)
const fetchWeather = createStep({
  id: 'fetch-weather',
  description: 'Fetches weather forecast for a given city',
  inputSchema: z.object({
    city: z.string(),
  }),
  outputSchema: z.object({
    location: z.string(),
    temperature: z.number(),
    conditions: z.string(),
    precipitationChance: z.number(),
  }),
  execute: async ({ inputData }) => {
    // ... (fetch logic) ...
    return {
      location: name,
      temperature: weather.current.temperature_2m,
      conditions: getWeatherCondition(weather.current.weather_code),
      precipitationChance: weather.daily.precipitation_probability_mean[0],
    };
  },
});

// Step 2: Agent suggests activities (Creative)
const activityPlanner = new Agent({
  id: 'activity-planner-agent',
  name: 'Activity Planner',
  instructions: `You are a local activities expert. Based on weather conditions, suggest 3-5 appropriate activities.
    - For rain (>50% precipitation), prioritize indoor activities
    - For extreme temperatures, consider climate-appropriate options
    - Always include one adventurous and one relaxing option`,
  model: openai('gpt-5'),
});

const planActivities = createStep({
  id: 'plan-activities',
  description: 'Uses AI to suggest activities based on weather',
  inputSchema: z.object({
    location: z.string(),
    temperature: z.number(),
    conditions: z.string(),
    precipitationChance: z.number(),
  }),
  outputSchema: z.object({
    activities: z.string(),
  }),
  execute: async ({ inputData }) => {
    const prompt = `Weather in ${inputData.location}: ${inputData.temperature}°C...`;
    const response = await activityPlanner.generate(prompt);
    return { activities: response.text };
  },
});

// The Pipeline
export const activityPlannerWorkflow = createWorkflow({
  id: 'activity-planner',
  inputSchema: z.object({ city: z.string() }),
  outputSchema: z.object({ activities: z.string() }),
})
  .then(fetchWeather)
  .then(planActivities);

activityPlannerWorkflow.commit();
```

**Why this works:** The LLM never hallucinates the weather. It is fed ground-truth data from Step 1.

---

## Memory: Stop Burning Tokens

I see this mistake constantly: developers sending the *entire* conversation history with every request.

**Stop it.**

It's slow. It's expensive. And as context fills up, the model gets stupider (the "lost in the middle" phenomenon).

Mastra gives you structured memory out of the box.

### Setting Up Memory

```typescript
// src/mastra/agents/memory-agent.ts
import { Agent } from '@mastra/core/agent';
import { Memory } from '@mastra/memory';
import { LibSQLStore } from '@mastra/libsql';

export const memoryAgent = new Agent({
  id: 'memory-agent',
  name: 'Memory Agent',
  instructions: 'You are a helpful assistant with perfect recall of our conversations.',
  model: openai('gpt-5'),
  memory: new Memory({
    storage: new LibSQLStore({
      id: 'memory-agent-store',
      url: 'file:../mastra.db',
    }),
    options: {
      lastMessages: 20,  // Keep last 20 messages in context
      semanticRecall: {
        enabled: true,  // Use embeddings to find old stuff
        topK: 5,
        threshold: 0.7,
      },
    },
  }),
});
```

### Semantic Recall is Magic

Working memory (last 20 messages) differs from Semantic Recall.

If a user asks about a restaurant recommendation from three weeks ago, **Working Memory** won't see it. But **Semantic Recall** will:
1.  Embed the user's question.
2.  Search the vector database for related past messages.
3.  Inject *only* those relevant messages into the context.

This makes your agent feel infinitely smart without an infinite bill.

---

## Agent Networks: The Final Boss

Using **Agent Networks** allows the LLM to act as a traffic controller, delegating tasks to specific agents or workflows.

Unlike a linear Workflow, a Network is dynamic.

```typescript
export const coordinatorAgent = new Agent({
  id: 'coordinator-agent',
  name: 'Research Coordinator',
  instructions: `You are a network of researchers and writers.
    - Use researchAgent for gathering facts
    - Use writingAgent for producing final content
    - Use weatherTool for current weather data
    - Use activityPlannerWorkflow for location-based planning
    
    Always produce comprehensive, well-structured responses.`,
  model: openai('gpt-5'),
  
  // Available primitives
  agents: { researchAgent, writingAgent },
  workflows: { activityPlannerWorkflow },
  tools: { weatherTool },
  
  // Network requires memory
  memory: new Memory({
    storage: new LibSQLStore({ id: 'network-store', url: 'file:../network.db' }),
  }),
});
```

When you query this network, the "Coordinator" decides:
*   "I need facts" -> Calls `researchAgent`.
*   "I need weather-based plans" -> Runs `activityPlannerWorkflow`.
*   "I need to write the report" -> Calls `writingAgent`.

It is efficient because specialized agents are better than one massive, generic prompt.

---

## The Bottom Line

Real production AI systems are not just a `while(true)` loop calling an LLM.

They are **architectures**.

*   Use **Workflows** when you need guarantees.
*   Use **Memory** to manage context and cost.
*   Use **Networks** to handle complexity.

Stop building toys. Start orchestrating.

### Resources

- [Mastra Workflows Documentation](https://mastra.ai/docs/workflows/overview)
- [Mastra Memory Documentation](https://mastra.ai/docs/memory/overview)
- [Full Demo Code](https://github.com/justsml/mastra-examples)

## Read the Series

1. [LLM Routing](/llm-routing-mastra-ai)
2. [Security & Guardrails](/mastra-security-guardrails)
3. [MCP & Tool Integrations](/mastra-mcp-tool-integrations)
4. **Workflows & Memory** (This Post)
