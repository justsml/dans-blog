---
title: "There's a wave of database innovation in 2025"
subTitle: "And you can blame AI."
date: 2025-09-10
modified: 2025-09-15
tags: [serverless, databases, AI, innovation, chroma, lanceDB, pagefind, orama]
category: Search
subCategory: "Object Stores"
# social_image: data-city-square-200.webp
cover_full_width: data-city-wide.webp
cover_mobile: data-city-square-200.webp
cover_icon: data-city-square-200.webp
cover_credit: "©️ 2025 Dan Levy"
---

# Not another Vector DB article

The database landscape has fundamentally shifted. Largely driven by the needs of AI applications, from vector-based RAG (Retrieval-Augmented Generation) to multi-modal (audio & video) searching. Sure, Postgres/PGVector, Sqlite, and Elasticsearch remain the backbone of enterprise search. But they come with significant operational overhead and complexity. Only the most important business use cases justify the extra engineering effort. (That's why you can always search for new products and never run out of results to buy, but good luck finding a specific order you placed years ago. Order history just doesn't bring in the $$$. Try any ecom site, go ahead, I'll wait.)

Before you deploy that massive Elasticsearch or Postgres cluster, or decide against a search feature due to classic DB costs, read this article to explore a fascinating newer class of DBs: **built on top of object-based storage & HTTP!** (like AWS S3, Cloudflare's R2, Backblaze B2, etc.)

## A database by any other name...

> I don't know if there's a good name for these DB tools. Since `NoSQL` was taken, maybe `Client Only`? `Edge Search`? Not sure about the SEO on those actually. How about `NoOps`? I got NoIDEA. Anyway, I have an article to return to...

Whatever they are called, **these serverless and CDN-capable datastores** are transforming how I think about search-based features for smaller- to mid-scale use cases. Including anything with roughly **1,000-1,000,000 records (or up to several GBs)** that previously didn't justify the engineering overhead of building costly search experiences.

## With neighbors like these, who needs AWS RDS?

One of the most overlooked aspects of these new datastores is their ability to provide multi-tenant isolation. This likely improves your security posture, reduces costs, and provides stable performance & reliability.

For example, you can create a separate database per customer, and store each in its own S3 bucket and path. This avoids the complexity of multi-tenant databases, and allows for easier data compliance.

## The grand tour: Pagefind, Orama, Chroma, and LanceDB

Each of these tools emphasizes a different aspect of the serverless search paradigm, but they all share a common goal: making search and data retrieval portable, faster, easier, and more flexible.

What makes these tools intriguing isn't just a few technical capabilities, but their deployment philosophy. They **cost close to nothing** when at rest. They run closer to the edge, **eliminate infrastructure**, support **advanced indexes**, and enable developers to ship modern search features that feel magical.

{/* Whether you're building a documentation site that needs instant search, an e-commerce store requiring semantic product discovery, or an AI application demanding vector similarity matching, these tools deliver enterprise-grade search with static site simplicity. */}

{/* > There will surely be more options in the future, if you have any suggestions or feedback please comment or reach out! */}

- **Pagefind** represents the pure static approach - compile once, search forever, with zero backend requirements.
- **Orama** offers the Swiss Army knife solution, running everywhere from browsers to serverless functions with remarkable performance.
- **Chroma** dominates the AI-native space, purpose-built for RAG applications with 22.9K GitHub stars and massive developer adoption.
- **LanceDB** brings enterprise-grade multimodal (multi-media) capabilities with a disk-based architecture that scales beyond memory limits.

To appreciate how far we've come, consider **fuse.js** - the old guard of client-side search that requires downloading entire datasets to browsers and struggles beyond basic fuzzy matching. The contrast illuminates just how sophisticated these modern alternatives have become.

### Battle of the Checkboxes

| Feature | [Pagefind](https://pagefind.app) | [Orama](https://orama.com) | [Chroma](https://www.trychroma.com/) | [LanceDB](https://lancedb.com) | [Fuse.js](https://fusejs.io) |
|---------|----------|--------|---------|----------|---------|
| **OpenSource Status** | MIT (100% open) | Apache 2.0 (open core) | Apache 2.0 (100% open) | Apache 2.0 (open core) | Apache 2.0 (100% open) |
| **Hosting Options** | Self-hosted, Static only | Self-hosted + Cloud | Self-hosted + Cloud | Self-hosted + Cloud | Client-side only |
| **GitHub Stars** | Active (CloudCannon) | **8K stars** | **22.9K stars**, 5M+ downloads | **8K stars** | **19K stars** |
| **Last Update** | v1.4.0 (active) | Continuous releases | Weekly releases | Bi-weekly releases | v7.1.0 (Feb 2025) |
| **Storage Type** | Static JSON/WASM | Memory + plugins | SQLite + Parquet | Lance columnar format | In-memory only |
| **Write Support** | Build-time only | **Full CRUD** | **Full CRUD** | **Full CRUD** | Read-only |
| **Update Operations** | Full rebuild | Remove + insert | Native update/upsert | **Advanced CRUD + versioning** | Collection replacement |
| **Query Languages** | String + filters | JavaScript API | Python/JS/REST + **SQL** | **SQL + vector + REST APIs** | Basic fuzzy search |
| **Scalar Indexing** | ✅ Metadata fields | ✅ All types | ✅ Metadata | ✅ **BTREE + BITMAP** | ✅ Basic fields |
| **Full-Text Search** | ✅ **Advanced stemming** | ✅ **BM25, 30 languages** | ✅ SQLite FTS | ✅ **Tantivy** and **Native** | ✅ Fuzzy only |
| **Vector/ANN Search** | ❌ | ✅ **Cosine similarity** | ✅ **HNSW** | ✅ **IVF_PQ, HNSW, GPU** | ❌ |
| **Spatial Indexing** | ❌ | ✅ **Geosearch** | ❌ | ✅ **Point clouds** | ❌ |
| **Hybrid Indexing** | ❌ | ✅ **Auto-optimization** | ✅ **Vector + metadata + FTS** | ✅ **Multimodal indexes** | ❌ |
| **Multilingual** | **40+ languages** | **30 languages, 8 alphabets** | Embedding model dependent | UTF-8, multilingual FTS | Basic Unicode |
| **Write Performance** | Fast build (2k pages/2s) | Near-instant | Optimized incremental | **Hundreds of TPS** | Synchronous blocking |
| **Query Performance** | Sub-100ms | **0.001ms - 181ms** | Sub-100ms | **3-5ms vector search** | 200-500ms (10k records) |
| **AI/RAG Integration** | None | ✅ **Built-in RAG pipeline** | ✅ **LangChain, LlamaIndex** | ✅ **Advanced RAG + reranking** | None |

### Code comparison: Implementation approaches

The syntax differences reveal each tool's philosophy and target use case:

#### Static site search with Pagefind
```html
<!-- Zero-config setup for static sites -->
<link href="/pagefind/pagefind-ui.css" rel="stylesheet">
<script src="/pagefind/pagefind-ui.js"></script>
<div id="search"></div>
<script>
  new PagefindUI({ element: "#search" });
</script>
```

#### Universal search with Orama
```javascript
import { create, insert, search } from '@orama/orama'

const db = create({
  schema: {
    title: 'string',
    content: 'string', 
    embedding: 'vector[1536]'
  }
})

await insert(db, { 
  title: 'Getting Started',
  content: 'Learn the basics',
  embedding: await generateEmbedding('Learn the basics')
})

const results = await search(db, { 
  term: 'basics',
  mode: 'hybrid' // Combines text + vector search
})
```

#### AI-native search with Chroma  
```typescript
import { ChromaClient } from "chromadb";

// RAG-ready setup
const client = new ChromaClient();
const collection = await client.createCollection({
  name: "knowledge-base"
});

// Add documents with automatic embedding
await collection.add({
  documents: ["AI will transform software development"],
  metadatas: [{ source: "tech-blog", category: "AI" }],
  ids: ["doc1"]
});

// Semantic search with metadata filtering
const results = await collection.query({
  queryTexts: ["future of programming"],
  where: { category: "AI" },
  nResults: 5
});
```

#### Enterprise-grade multimodal with LanceDB
```typescript
import * as lancedb from "@lancedb/lancedb";
import "@lancedb/lancedb/embedding/openai";
import { LanceSchema, getRegistry } from "@lancedb/lancedb/embedding";
import { Utf8 } from "apache-arrow";

const db = await lancedb.connect("data/multimodal-db");
const func = getRegistry()
  .get("openai")
  ?.create({ model: "text-embedding-ada-002" });

// Schema with automatic embedding generation
const documentsSchema = LanceSchema({
  text: func.sourceField(new Utf8()),
  vector: func.vectorField(),
  category: new Utf8()
});

const table = await db.createEmptyTable("documents", documentsSchema);
await table.add([
  { text: "machine learning concepts", category: "research" },
  { text: "deep learning fundamentals", category: "research" }
]);

// SQL + vector search combination
const results = await table.search("machine learning concepts")
  .where("category = 'research'")
  .limit(10)
  .toArray();
```

## RAG for the rest of us

The standout feature differentiating modern tools from legacy solutions is their **native AI integration**. Three of these tools have built specifically for the AI application era:

**Orama** ships with a complete RAG pipeline in v3.0+, including answer sessions, secure proxy plugins, and automatic embedding generation. The OramaCore server even includes **built-in LLMs** for local inference, achieving 1-second time-to-first-token compared to 5 seconds for external APIs.

**Chroma** has become the go-to choice for AI developers, with **first-class integrations** for LangChain, LlamaIndex, and Haystack. Its 22.9K GitHub stars and 5M+ monthly downloads reflect massive adoption in the RAG ecosystem. The recent v0.4 architectural simplification made it even more production-ready.

**LanceDB** brings enterprise-grade AI capabilities with **sophisticated reranking**, cross-encoder support, and multimodal embedding management. Its disk-based architecture scales to billions of vectors while maintaining 3-5ms vector search performance.

### Performance Priority & Philosophy

Each tool optimizes for different performance profiles. **Orama** achieves sub-microsecond query times (0.001ms-181ms) through aggressive in-memory optimization and smart data structures. **Pagefind** prioritizes bandwidth efficiency, splitting indexes into chunks that load on-demand, making even large documentation sites feel instant.

**Chroma** focuses on RAG workload optimization, with incremental index updates and thread-safe concurrent operations. **LanceDB** takes a unique disk-first approach, delivering enterprise performance while scaling beyond memory limits - crucial for applications handling massive datasets.

The performance gap with legacy tools is stark. While fuse.js struggles with 200-500ms search times on 10K records, these modern alternatives consistently deliver sub-100ms experiences even on much larger datasets.

> If only Sqlite (with Vectors & FTS) weren't such a pain to get setup over a CDN...

## Choosing your Search Weapon

The decision comes down to three key factors: **data characteristics, deployment constraints, and AI requirements**. But let's get concrete about when to choose what.

### Start here: Match your use case

**Choose Pagefind when:**
- Building documentation sites, blogs, or knowledge bases
- Content updates happen weekly or less frequently
- You want zero operational overhead and perfect CDN caching
- Budget is tight and you need predictable costs
- *Example: A company documentation site with 10K+ pages that updates monthly*

**Choose Orama when:**
- Building dashboards, e-commerce, or user-facing applications
- You need real-time search updates and multi-environment deployment
- Performance is critical (sub-100ms response times required)
- You want one tool that works everywhere from browsers to edge functions
- *Example: A SaaS application with dynamic product catalogs and user search*

**Choose Chroma when:**
- Building RAG applications or AI-powered knowledge bases
- You need extensive LangChain/LlamaIndex integrations
- Semantic search and document similarity are core features
- You're prototyping AI applications and need fast iteration
- *Example: A customer support bot that searches company knowledge for contextual answers*

**Choose LanceDB when:**
- Working with multimodal data (images, audio, video alongside text)
- You need enterprise-grade performance at massive scale
- Complex analytics and reranking are requirements
- Budget allows for more sophisticated infrastructure
- *Example: A media platform enabling semantic search across millions of videos and transcripts*

## Executive Summary

In summary, the rise of serverless databases and edge-native search tools is reshaping the landscape of data retrieval and management. By leveraging modern architectures and eliminating operational overhead, these solutions empower developers to build sophisticated search experiences with unprecedented ease.

### The bigger picture: Search as a competitive advantage

These tools represent something more significant than incremental database improvements. They're **democratizing capabilities that were previously exclusive to tech giants, or limited to only the most critical app features**.

Consider the timeline: In 2020, implementing semantic search required a dedicated ML team, GPU clusters, and months of infrastructure work. Today, it's a trivial amount of code and less than a $5/month hosting bill.

### (Database) Objects May Be Closer Than They Appear

This isn't just about technical convenience—it's about **competitive dynamics**. Small teams can now ship search experiences that rival products built by hundred-person engineering teams. The moat around "sophisticated search" is evaporating.

That "nice-to-have" search feature you've been postponing? It's probably easier to implement than your login system now. The question isn't whether to build great search—it's which approach matches your current constraints and growth trajectory.

> Importantly, **user expectations have shifted**. Every search box is now compared to Google, GitHub, or Notion. Users expect instant results, typo tolerance, and semantic understanding. These tools make those expectations achievable without enterprise budgets.

### For those about to learn...

1. **Experiment this weekend**: Pick the tool that matches your current project and build a prototype. Most of these can be running in under an hour or two. (Feel free to check out my demo [Emoji Search example](https://github.com/justsml/emoji-brain/tree/main) using Pagefind.)
2. **Think beyond text search**: If you're building anything involving user-generated content, consider how semantic search might unlock new user experiences.
3. **Start simple, plan for growth**: Begin with static approaches like Pagefind, but architect your data layer to support future migration to more dynamic solutions.

{/* The database landscape will continue evolving, but the trend is clear: **sophisticated search is becoming a commodity**. The competitive advantage lies not in *having* great search, but in *how creatively you apply it* to solve real user problems. */}

*Want to dive deeper? Check out my [practical guide to implementing Pagefind][1] for a hands-on starting point, or explore the growing ecosystem of edge-native databases that are reshaping how we think about data at scale.*

> **Disclaimer:** I've used Pagefind for several years. And in 2025, I also became a contributor! I've [experimented with](https://emoji-brain.netlify.app/) Orama and Chroma for [smaller projects](https://emoji-brain.vercel.app/), and I'm currently exploring LanceDB for a larger AI application. I have no financial ties to any of these projects, just a keen interest in the evolving database landscape.

[1]: https://danlevy.net/you-might-not-need-algolia/
