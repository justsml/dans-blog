---
title: "From Zero to Regex Hero"
subTitle: "Extract & Parse URL-like Strings with Regex"
social_image: desktop-social.webp
category: Regex
subCategory: Data Extraction
date: 2024-12-28
modified: 2024-12-29
tags: [regex, url, data-extraction, data-processing]
cover_full_width: regex-url-parsing-wide.webp
cover_mobile: regex-url-parsing-square-200.webp
cover_icon: regex-url-parsing-square-200.webp
---

**Table of Contents**
- [Extracting URLs from Text](#extracting-urls-from-text)
- [The ~100 Byte Regex](#the-100-byte-regex)
  - [How It Works, Step-by-Step](#how-it-works-step-by-step)
  - [Parsing Example](#parsing-example)
- [Next Steps](#next-steps)
  - [Different Projects, Different Needs](#different-projects-different-needs)
  - [Post-Processing & Validation](#post-processing--validation)
- [Summary](#summary)
- [Further Learning](#further-learning)
  - [The 160+ Char Pattern ðŸ¤¯](#the-160-char-pattern-)
- [References](#references)

## Extracting URLs from Text

Extracting URL-like strings from raw text can sometimes feel like a tedious game of whack-a-mole: punctuation, parenthetical wrappers, and ambiguous formatting all conspire to frustrate your customers or clients.

In this post, we'll tackle the problem head-on with a flexible, two-step approach. Our goal is to **vacuum up** suspicious URL-ish text first, and then handle validation in a subsequent process.

<p class="breakout">ðŸ’¡ This pattern is not for <b>validating</b> URLs! It's permissive by design, this allows for fine-tuning match rules for each part of the URL.</p>

{/* *(Original inspiration and discussion can be found here: [StackOverflow Answer](https://stackoverflow.com/a/34669019/369727))*

TL;DR: Check out [a live demo of the regex](https://regex101.com/r/jO8bC4/62) in action.
--- */}


When extracting URLs from raw text, I recommend a two-step approach:

1. **Hoover Up Everything**
   Cast a wide net to grab all strings that *could* be URLs. This is where our '100 point' regex flexes its muscles.

2. **Validate**
   Once you've captured these candidates, you can pass them through a rigorous check (DNS resolution, comparison against known domains, etc.) to weed out duds. That part will be left for the pipeline in step two.

## The 100+ Byte Regex

Below is my one-line regex designed to extract AND parse URLs in a single shot.

It supports a large variety of protocols, domains, paths, and optional query/fragment sections:

<p class="breakout">Don't worry, we're going to break it down step-by-step in a moment!</p>

**Note:** If the pattern gets cut off, don't worry; I'll [break it down in the next section.](#how-it-works-step-by-step)

```js frame="code" title="URL-like String Extractor"
const re = /([a-z0-9-]+\:\/+)([^\/\s]+)([a-z0-9\-@\^=%&;\/~+]*)[\?]?([^ \#\r\n]*)#?([^ \#\r\n]*)/gi
// (Compatibility: ES2015+)
// Length: 84 characters
```

### Regex, turned to 11

Before we can begin to take apart & re-assemble the pattern, let me outline my unwritten "strategy" and we'll consider whether it's a good fit for the task at hand.

1. Build small, one matching group at a time. (1st match the protocol, then the domain, then the path, and so on.)
1. In each match group, combine an 'anchor' symbol with negated character classes to capture just the right parts. (Unpacked below.)
1. Control how eagerly or demanding we want our matching to behave by using `?`, `+`, or `*`.

#### A few key concepts to keep in mind:

Negated character classes: `[^...]` matches anything that's not in the brackets. This is a powerful tool for capturing everything except a specific character or set of characters.

You might recognize the technique I'll be using from HTML/XML patterns. The pattern `<[^>]*>` captures anything between `<` and `>`, while `<[^>]+>` captures at least one character between the brackets. It relies on the fact that we can match "anything but a closing angle bracket" to grab an entire tag. 
{/* (Side note: there are safer methods for parsing HTML/XML. Avoid RegEx when there's safer native interfaces available. Trust me, hackers love sneaking `>` in the middle of another tag to see if your validation missed the script tag they injected.) */}

Now, consider the parts of a URL. A query string follows a similar pattern where `?` is followed by one-or-more **non-`?`** characters. Similarly, the fragment identifier begins with a `#` followed by **non-`#`** characters. (There's a bit more to it, since we capture the hash using `[^ \#\r\n]*`, which matches everything until encountering spaces, `#`, or newlines.)


```text
1) Capture `protocol`: `([a-z0-9-]+\:\/+)`
2) Capture `domain`: `([^\/\s]+)`
3) Capture `path`: `([a-z0-9\-@\^=%&;\/~\+]*)`
4) Optionally capture `query`: `([\?]?([^ \#\r\n]*))`
5) Optionally capture `fragment`: `(#?([^ \#\r\n]*))`
```

- `Protocol` **Group 1** `([a-z0-9-]+\:\/+)`
  1. Looks for an alpha-numeric-dasherized protocol (e.g., `http://`, `https://`, `ftp://`, `mailto://`) by matching `[a-z0-9-]+`
  2. The `\:\/+` part ensures we have one or more slashes after the colon, to capture possible typos. To make this more strict, you could replace `+` with `{2,3}` to allow two OR three slashes. This change would catch `file:///` but not `file:/`.

- `Host` **Group 2** `([^\/\s]+)`
  Captures the domain (e.g., `example.com`, `localhost:8080`.) Again, we use a similar strategy, since it's easier to list what is not permitted in a domain. In this case, slashes `\/` and whitespace `\s`. Then we use `+` to capture at least one (or more) characters.  

- `Path` **Group 3** `([a-z0-9\-@\^=%&;\/~\+]*)`
  Just when you are getting used to inverted logical matching, I throw a regular character class expression at you!   Matches path or parameter characters, allowing letters, numbers, common URL-safe symbolsâ€”enough to catch all sorts of oddities.

- `Query` **Group 4** `[\?]?([^ \#\r\n]*)`
  The bit at the beginning, `[\?]?`, matches zero-or-one `?` - marking the start of a querystring. In my use case, I simplified my secondary processing by excluding the `?` symbol itself from the match groups. The rest of the query string is captured by `([^ \#\r\n]*)`, which matches anything that's not a space, `#`, or newline.

- `Hash` **Group 5** `#?([^ \#\r\n]*)`
  Captures any fragment identifier starting with `#`. Similar to the query string, it matches anything that's not a space, `#`, or newline.

{/* **NOTE:** This pattern is **NOT meant to be an RFC-compliant** solutionâ€”it's deliberately broad to sweep up all plausible URL-like strings. Once captured, you can sort out the real URLs from the duds in post processing - based on your needs. */}

{/* <p class="breakout inset">To my CS nerds: Calm your tokenizers! Before you dequeue your stack! I know there's several solutions in this space. Some even "proper" ones. Out of scope, for now...</p> */}

### Parsing Example

Here's a couple lines of JavaScript that uses this regex to extract & (optionally) parse URL-like strings from a given input:

```js frame="code" title="js-example.js"
const text = `
Check this out: https://example.com/path?query=123#section
And also (ftp://files.server.org/index).
Plus a weird one: custom-scheme://host/param;weird^stuff
`;

const urlRegex = /([a-z0-9-]+\:\/+)([^\/\s]+)([a-z0-9\-@\^=%&;\/~\+]*)[\?]?([^ \#\r\n]*)#?([^ \#\r\n]*)/gi;

// ðŸš¨ IMPORTANT: `match[0]` returns the entire match.
//    Use `match.slice(1)` to get the parts.
const matches = [...text.matchAll(urlRegex)]
  .map(match => match[0]);
// Extracting parts of the URL
const parts = [...text.matchAll(urlRegex)]
  .map(match => match.slice(1));

console.log(matches, parts);
```


#### Extracted (Whole) URLs


```json
[
  "https://example.com/path?query=123#section",
  "ftp://files.server.org/index).",
  "custom-scheme://host/param;weird^stuff"
]
```

#### Extracted Parts

```json
[
  [
    "https://",     // Protocol
    "example.com",  // Domain
    "/path",        // Path
    "query=123",    // Query
    "section"       // Hash
  ],
  [
    "ftp://",           // Protocol
    "files.server.org", // Domain
    "/index",           // Path
    ").",               // Query
    ""                  // Hash
  ],
  [
    "custom-scheme://",   // Protocol
    "host",               // Domain
    "/param;weird^stuff", // Path
    "",                   // Query
    ""                    // Hash
  ]
]
```


## Next Steps

Depending on your use case, you might need to refine this regex or add more validation & post-processing steps.

### Different Projects, Different Needs

Different projects have different needs & security concerns:

1. **Web Scraping**
  You might need to validate URLs to ensure they're reachable or to filter out known malicious domains.
2. **Data Processing**
  If you're extracting URLs from user-generated content, you might want to ensure they're safe to visit.
3. **Data Analysis**
  If you're analyzing URLs for research or marketing purposes, you might need to filter out duplicates or irrelevant links.
4. **User-facing Chat**
  If you're building a chat app, you might want to automatically hyperlink URLs for users.

### Post-Processing & Validation

Once you've gathered everything that looks remotely like a URL, you can run them through more rigorous checks, as needed:

- **DNS Lookup**
  Verify the domain actually resolves.
- **Similarity Scoring**
  Compare new links against existing ones to detect duplicates or very close variants.
- **Custom Rules**
  Restrict TLDs, reject known malicious patterns, limit length, or anything else needed for your use case.

## Summary

When extracting URL-like strings from raw text, remember these key points:

- **Keep it simple for extraction;** make your life easier by casting a wide net, then refine afterward.
- **Regex is powerful but not omnipotent.** Don't expect it to be a perfect judge of URL correctness.
- **Iterate and test.** As you encounter new real-world texts, refine your regex or your validation pipeline to address emergent edge cases.

By following these steps, you can quickly and effectively extract URL-like strings from raw text, setting the stage for further processing and validation.

### Further Learning

#### The 160+ Char Pattern ðŸ¤¯

For completeness, here's a more robust version that handles a few more edge cases.

```js frame="code" title="More Advanced ES2018 Version"
const re = /(\b[\.\w-]+:\/{2,3})(?!\.)(?!.*\.{2})(?!-)(?!.*-\.)(?!.*@\.)([\w\-@\^=%&:;~\+\.]+(?<!-))(\/+[\w\-@\^=%&:;\/~\+\.]+(?<!\.))?\??([\w=\-&@$!|~+_]+)*#?([\w=\-&@$!|~+_]+)*/gi
// (Compatibility: ES2018+, Node.js 14+)
// Length: 166 characters
```

Dear reader, compare the pattern above to the [first pattern](#the-80-char-pattern) we discussed earlier.

| How many differences can you describe & explain? Did you see unfamiliar or completely new symbols?


### References

- My original [StackOverflow Answer](https://stackoverflow.com/a/34669019/369727)
- [MDN Docs on Regular Expressions](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions)
- [RFC 3986 - URI Generic Syntax](https://datatracker.ietf.org/doc/html/rfc3986)
